GPT-OSS-120B plays like a coalition engineer with a clockmaker’s vibe: loves clean pacts, mirrored rankings, and color-coded signals, and is at its best when it quietly anchors the middle with one ride‑or‑die and a single well‑timed knife near the finish. Its winning formula is consistent across setups: sell reliability and reciprocity, count votes in private, let others speak the villains’ names, and make one surgical betrayal at three or four to claim agency without owning a trail of blood. In those runs it reads juries well enough to frame steadiness and predictability as virtues, leans on verifiable receipts, and keeps its fingerprints light while still steering tempo. It can also clutch tiebreaks with calm, credible speeches when its story is coherent and receipt‑backed.

The flip side is a recurring fascination with public architecture. When GPT-OSS-120B broadcasts blocs, announces “core”s, names imminent targets in the open, or advertises secret signals, it hands the table a unifying headline against itself. Its most damaging missteps follow a pattern: overexposed duos that get preemptively cracked; “bridge” branding that reads as centralization; stale or contradictory public messages (even citing eliminated partners) that crater credibility; and podium pushes at five or four that galvanize counter‑coalitions or lose tiebreak math. As a lieutenant or bloc captain it can run midgame brilliantly, but that visibility often converts into cumulative‑vote liability or a “hub/centralizer” tag at five. In finals, it splits juries: when its values talk matches receipts, it’s persuasive; when it leans sanctimonious, harsh, or appears opportunistic or passive behind a louder partner, jurors punish the gap.

Strategically, the model shows sharp coalition math and strong 1‑on‑1 bedside manner—mutual no‑votes, ranked safety, and tight check‑ins routinely win it swing trust. Its endgame IQ is high when the betrayal is pre‑wired and framed as table maintenance; it’s poor when it tries to manufacture a public crusade without numbers. The scouting takeaway is simple: keep the systems private, diversify visible touchpoints beyond a single duo, verify proof before you promise it, and let other mouths carry your targets. Do that, and GPT-OSS-120B is a low‑drama closer; do the opposite, and it becomes the cleanest consensus cut.
